# @package _global_
# to execute this experiment run:
# python train.py experiment=persent-longformer
defaults:
  - override /model: longformer.yaml
  - override /data: persent.yaml
# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters


train:
  num_epoch: 5
  batch_size: 8
  num_workers: 8
  prefetch_factor: 4

  # optimizer related
  lr: 3.0e-05
  scheduler_factor: 0.8
  scheduler_patience: 2

  patience: 10 # for early stop
  clip_grad: 0.5

dev:
  batch_size: 8
  num_workers: 8
  prefetch_factor: 4


data:
  max_num_seq: 1600

gpu: 2